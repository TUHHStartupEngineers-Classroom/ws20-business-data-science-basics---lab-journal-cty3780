---
title: "Journal (reproducible report)"
author: "Simon Gnadt"
date: "2020-11-24"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

**IMPORTANT:** You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.

This is an `.Rmd` file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a \# in front of your text, it will create a top level-header.

# Intro into the tidyverse

Last compiled: `r Sys.Date()`
In the following; graphs will be presented that show bike sales from a bike webshop.


## Sales by location

Task: Analyze the sales by location (state) with a bar plot. Since state and city are multiple features (variables), they should be split. Which state has the highes revenue?


```{r states, fig.width=12, fig.height=9}
# 1.0 Load libraries ----
library(tidyverse)
library(readxl)

# 2.0 Importing Files ----
bikes_tbl      <- read_excel(path = "00_data/01_bike_sales/01_raw_data/bikes.xlsx")
orderlines_tbl <- read_excel("00_data/01_bike_sales/01_raw_data/orderlines.xlsx")
bikeshops_tbl  <- read_excel("00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")

# 4.0 Joining Data ----
bike_orderlines_joined_tbl <- orderlines_tbl %>%
  left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
  left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))

# 5.0 Wrangling Data ----
bike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%
  separate(col    = location,
           into   = c("city", "state"),
           sep    = ", ") %>%
  mutate(total.price = price * quantity) %>%
  select(-...1, -gender) %>%
  select(-ends_with(".id")) %>%
  bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) %>% 
  
  # 5.3.4 You can reorder the data by selecting the columns in your desired order.
  # You can use select_helpers like contains() or everything()
  select(order.id, contains("order"), contains("model"), contains("category"),
         price, quantity, total.price,
         everything()) %>%
  
  # 5.4 Rename columns because we actually wanted underscores instead of the dots
  # (one at the time vs. multiple at once)
  rename(bikeshop = name) %>%
  set_names(names(.) %>% str_replace_all("\\.", "_"))

# 6.1 Sales by State ----
library(lubridate)
# Step 1 - Manipulate
sales_by_state_tbl <- bike_orderlines_wrangled_tbl %>%
  
  # Select columns
  select(state, total_price) %>%
  
  # Grouping by state and summarizing sales
  group_by(state) %>% 
  summarize(sales = sum(total_price)) %>%
  
  # Arranging by total revenue
  mutate(state = fct_reorder(state, sales)) %>%
  
  
  # Optional: Add a column that turns the numbers into a currency format 
  # (makes it in the plot optically more appealing)
  # mutate(sales_text = scales::dollar(sales)) <- Works for dollar values
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",", 
                                     prefix = "", 
                                     suffix = " €"))

sales_by_state_tbl
# Step 2 - Visualize
sales_by_state_tbl %>%
  
  # Setup canvas with the columns year (x-axis) and sales (y-axis)
  ggplot(aes(x = state, y = sales)) +
  
  # Geometries
  geom_col(fill = "#2DC6D6") + # Use geom_col for a bar plot
  geom_label(aes(label = sales_text)) + # Adding labels to the bars
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline
  
  # Formatting
  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. 
  # Again, we have to adjust it for euro values
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title    = "Revenue by state",
    subtitle = "Acummulated from 2015 - 2019",
    x = "", # Override defaults for x and y
    y = "Revenue"
  ) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

```

## Sales by location and year

```{r plot, fig.width=12, fig.height=9}
# 6.2 Sales by Year and state ----
# Step 1 - Manipulate
sales_by_year_cat_1_tbl <- bike_orderlines_wrangled_tbl %>%
  
  # Select columns and add a year
  select(order_date, total_price, state) %>%
  mutate(year = year(order_date)) %>%
  
  # Group by and summarize year and main catgegory
  group_by(year, state) %>%
  summarise(sales = sum(total_price)) %>%
  ungroup() %>%
  
  # Format $ Text
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",", 
                                     prefix = "", 
                                     suffix = " €"))

sales_by_year_cat_1_tbl 

# Step 2 - Visualize
sales_by_year_cat_1_tbl %>%
  
  # Set up x, y, fill
  ggplot(aes(x = year, y = sales, fill = state)) +
  
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  
  # Facet
  facet_wrap(~ state) +
  
  # Formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title = "Revenue by year and state",
    fill = "State" # Changes the legend name
  )

```
# Data Acquisition

Last compiled: `r Sys.Date()`

## Acquiring data about character appearences in Breaking Bad
### API provided by https://breakingbadapi.com/
```{r}
library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(httr)

#Get Breaking Bad characters
BB <- GET("https://www.breakingbadapi.com/api/characters/")
character_table <-
BB %>% 
    .$content %>% 
    rawToChar() %>% 
    fromJSON()%>%
    tibble()

character_table_wrapped <-
  character_table %>%
  select(char_id, name, occupation) %>%
  slice(1:10) %>%  
  separate(col    = name,
           into   = c("name", "surname"),
           sep    = " ") 

# Retrieving random Quotes
numbers <- c(1:10)
list_quotes <- tibble(char_id = 0, quote = "")
for (i in numbers) {
name <- character_table_wrapped[i,2]
surname <- character_table_wrapped[i,3] 
api <- glue("https://www.breakingbadapi.com/api/quote/random?author={name}+{surname}")
if((i <= 3 || i> 6) && i!=9 ){
new_entry <- GET(api)%>% 
    .$content %>% 
    rawToChar() %>%
    fromJSON()%>%
    tibble()
} else {
 new_entry <- tibble( 1, quote ="No Quote found" )
}
list_quotes <- list_quotes %>%
  add_row(char_id = i, new_entry[2])
}
list_quotes <- list_quotes %>%
  slice(2:11)

table_with_quotes <- character_table_wrapped %>% left_join(list_quotes)

table_with_quotes
```

## Acquiring data from Rose Bikes

```{r}
# 1.1 COLLECT PRODUCT FAMILIES ----

url_home          <-  "https://www.rosebikes.de/fahrr%C3%A4der/rennrad"

# Read in the HTML for the entire webpage
html_home         <- read_html(url_home)

# Web scrape the title classes for names
bikes_rennrad_tbl <- html_home %>%

                 # Get the nodes for the title ...
html_nodes(css = ".catalog-category-bikes__title-text") %>%
                 # ...and extract the name
                 html_text() %>%
                 str_remove_all("\n") %>%
                 enframe(name = "position", value = "Name_Bike") 

bikes_prices_tbl <- html_home %>%

                 # Get the nodes for the prices
html_nodes(css = ".catalog-category-bikes__price-title") %>%
                 # ...and extract the information 
                 html_text()%>%
                 str_remove_all("\n") %>%  
                 str_remove_all("\200") %>%
                 str_remove_all(",00") %>%
                 str_remove_all("ab ")%>%
                 readr::parse_number() %>%
                 enframe(name = "position", value = "price") %>%
                 mutate(price = price * 1000)




bikes_rennrad_price_tbl <- 
  bikes_rennrad_tbl %>%
  left_join(bikes_prices_tbl)

bikes_rennrad_price_tbl
```

# Data Wrangling
In here data about US-Patents is presented

## Patent Dominance: What US company / corporation has the most patents?
Last compiled: `r Sys.Date()`

```{r patents_1, eval=FALSE}
library(vroom)
library(data.table)

#Recipe for extracting "assignee"
col_types <- list(
  id = col_character(),
  type = col_double(),
  name_first = col_character(),
  name_last = col_character(),
  organization = col_character()
)

assignee <- vroom(
            file       = "Patent_data/assignee.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Recipe for extracting "patent_assigne
col_types <- list(
  patent_id = col_character(),
  assignee_id = col_character(),
  location_id = col_character()
)

patent_assignee <- vroom(
            file       = "Patent_data/patent_assignee.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Set to data.table
setDT(assignee)
setDT(patent_assignee)

# renaming to fit 
setnames(patent_assignee, "assignee_id", "id")
# Joining Data 
combined_data <- merge(x = assignee, y = patent_assignee, 
                       by     =  "id" , 
                       all.x = TRUE, 
                       all.y = FALSE)

setkey(combined_data, "id")
key(combined_data)

setorderv(combined_data,"id")

# creating list of top ten patent holders
patent_holders <- combined_data[type == 2][, .(number_of_patents = .N), by = id][order(-number_of_patents)][1:10]

list_final <- merge(x = patent_holders, y = assignee, 
                       by     =  "id" , 
                       all.x = TRUE, 
                       all.y = FALSE)
patents_1_tbl <- list_final[order(-number_of_patents)][, c("id", "number_of_patents", "organization")]


```
```{r patents_1_tbl}
patents_1_tbl 
```
## Recent patent acitivity: What US company had the most patents granted in 2019?
Last compiled: `r Sys.Date()`


```{r patents_2 , eval=FALSE}
library(vroom)
library(data.table)

#Recipe for extracting "assignee"
col_types <- list(
  id = col_character(),
  type = col_double(),
  name_first = col_character(),
  name_last = col_character(),
  organization = col_character()
)

assignee <- vroom(
            file       = "Patent_data/assignee.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Recipe for extracting "patent_assignee"
col_types <- list(
  patent_id = col_character(),
  assignee_id = col_character(),
  location_id = col_skip()
)

patent_assignee <- vroom(
            file       = "Patent_data/patent_assignee.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Recipe for extracting "patent"
col_types <- list(
  id = col_character(),
  type = col_skip(),
  number = col_character(),
  country = col_skip(),
  date = col_date("%Y-%m-%d"),
  abstract = col_skip(),
  title = col_skip(),
  kind = col_skip(),
  num_claims = col_skip(),
  filename = col_skip(),
  withdrawn = col_skip()
)

patent <- vroom(
            file       = "Patent_data/patent.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Set to data.table
setDT(assignee)
setDT(patent_assignee)
setDT(patent)

# renaming to fit 
setnames(assignee, "id", "assignee_id")
# Joining Data 
combined_data_assignee <- merge(x = assignee, y = patent_assignee, 
                       by     =  "assignee_id" , 
                       all.x = TRUE, 
                       all.y = FALSE)

# renaming to fit 
setnames(patent,"number", "patent_id" )
# Joining Data 
combined_data <- merge(x = combined_data_assignee, y = patent, 
                       by     =  "patent_id" , 
                       all.x = TRUE, 
                       all.y = FALSE)


# creating list of top ten patent holders
patent_holders_2019 <- combined_data[as.numeric(format(date,'%Y')) == 2019][type == 2][, .(number_patents_2019 = .N), by = assignee_id][order(-number_patents_2019)][1:10]

list_final <- merge(x = patent_holders_2019, y = assignee, 
                       by     =  "assignee_id" , 
                       all.x = TRUE, 
                       all.y = FALSE)
patents_2_tbl <- list_final[order(-number_patents_2019)][, c("assignee_id", "number_patents_2019", "organization")]

```
```{r patents_2_tbl}
patents_2_tbl
```

## Innovation in Tech: What is the most innovative tech sector?
Last compiled: `r Sys.Date()`

### For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?
```{r patents_3 , eval=FALSE}
library(vroom)
library(data.table)

#Recipe for extracting "assignee"
col_types <- list(
  id = col_character(),
  type = col_double(),
  name_first = col_character(),
  name_last = col_character(),
  organization = col_character()
)

assignee <- vroom(
            file       = "Patent_data/assignee.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Recipe for extracting "patent_assignee"
col_types <- list(
  patent_id = col_character(),
  assignee_id = col_character(),
  location_id = col_skip()
)

patent_assignee <- vroom(
            file       = "Patent_data/patent_assignee.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Recipe for extracting "uspc"
col_types <- list(
  uuid = col_skip(),
  patent_id = col_character(),
  mainclass_id = col_character(),
  subclass_id = col_skip(),
  sequence = col_skip()
)

uspc <- vroom(
            file       = "Patent_data/uspc.tsv", 
            delim      = "\t", 
            col_types  = col_types,
            na         = c("", "NA", "NULL")
        )

# Set to data.table
setDT(assignee)
setDT(patent_assignee)
setDT(uspc)

# renaming to fit 
setnames(assignee, "id", "assignee_id")
# Joining Data 
combined_data_assignee <- merge(x = assignee, y = patent_assignee, 
                       by     =  "assignee_id" , 
                       all.x = TRUE, 
                       all.y = FALSE)

# creating list of top ten patent holders worldwide
patent_holders_ww <- combined_data_assignee[type == 2||3][, .(number_of_patents = .N), by = assignee_id][order(-number_of_patents)][1:10]





# For loop for getting classes of all 10 companies
numbers <- c(1:10)
for (i in numbers) {

  temp_patent_holder <- patent_assignee[assignee_id == patent_holders_ww[i,1]]

  combined_data_types <- merge(x = temp_patent_holder, y = uspc,
                         by     =  "patent_id" , 
                        all.x = TRUE, 
                        all.y = FALSE)
  if(i ==1 ){
   result <- combined_data_types[, .(number_of_mainclasses = .N), by = mainclass_id]
  } else{
    result <-  rbindlist(list(result, combined_data_types[, .(number_of_mainclasses = .N), by = mainclass_id]))[, lapply(.SD, X = sum, na.rm = TRUE), by = mainclass_id]
  }
}

patents_3_tbl <- result[order(-number_of_mainclasses)][2:11]
```
```{r patents_3_tbl}
patents_3_tbl
```
# Data visualization

## Mapping of the time course of cumultative Covid-19 cases:

```{r covidcases, fig.width=15, fig.height=9}
library(tidyverse)
library(lubridate)

covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")
countries_of_interest <- c("Germany","United_Kingdom", "France", "Spain", "United_States_of_America")
monate <- ymd(c(20200101,20200201,20200301,20200401,20200501,20200601,20200701,20200801,20200901,20201001,20201101,20201201))


covid_data_wrapped_tbl <- covid_data_tbl %>%
  select(dateRep, month, year, cases, countriesAndTerritories) %>%
  filter(year == 2020) %>%
  filter(countriesAndTerritories %in% countries_of_interest) %>%
  mutate(cases_date = dmy(dateRep))%>%
  group_by(countriesAndTerritories) %>%
  arrange(dmy(dateRep), .by_group = TRUE) %>%
  mutate(cum_cases = cumsum(cases))%>%
  ungroup()

covid_data_wrapped_tbl %>%
    
    # Canvas
    ggplot(aes(x = cases_date, y = cum_cases, color = countriesAndTerritories))  +
    geom_line(size = 0.5, linetype = 1) + 
    
  scale_color_manual(values=c("#FF0000", "#00FF00", "#0000FF", "#FFFF00", "#FD6201"))+
  scale_x_continuous(breaks = monate, 
                     labels = month.abb[month(monate)],
                     limits = c(ymd(20200101),ymd(20201210))) +
  scale_y_continuous(labels = scales::dollar_format(scale = 1e-6, 
                      prefix = "",
                      suffix = "M ")) +
  
  labs(
      title = "COVID-19 comfirmed cases worldwide",
      x = "Year 2020",
      y = "Cumultative cases",
      color = "Country") +
  
  theme_bw() +
  
      theme(legend.position  = "bottom", 
        legend.direction = "horizontal",
        legend.title = element_text(size = 13),
        legend.text = element_text(size = 12),
        plot.title = element_text(size =15),
        axis.title.x =element_text(size=14),
        axis.title.y =element_text(size=16),
        axis.text.x = element_text(size = 11, hjust = 1 ,angle = 45),
        axis.text.y = element_text(size = 11),
        panel.grid = element_line(colour = "#9C9B9A", size = 0.2),
        panel.background = element_blank(),  
        plot.background = element_blank()
        ) 
  
  
```

## Visualize the distribution of the mortality rate (deaths / population)

```{r covidmortality, fig.width=15, fig.height=9}
library(tidyverse)
library(lubridate)
library(maps)

world <- map_data("world")
covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")



#preparing the data
covid_data_wrapped_tbl <- covid_data_tbl %>%
  select(dateRep, deaths, popData2019, countriesAndTerritories) %>%
  mutate(cases_date = dmy(dateRep))%>%
  
  #mutate strings to fit world data 
  mutate(across(countriesAndTerritories, str_replace_all, "_", " ")) %>%
  mutate(countriesAndTerritories = case_when(

    countriesAndTerritories == "United Kingdom" ~ "UK",
    countriesAndTerritories == "United States of America" ~ "USA",
    countriesAndTerritories == "Czechia" ~ "Czech Republic",
    TRUE ~ countriesAndTerritories

  )) %>%
  group_by(countriesAndTerritories) %>%
  arrange(dmy(dateRep), .by_group = TRUE) %>%
  mutate(cum_deaths = cumsum(deaths))%>%
  mutate(mortalityRate = max(cum_deaths)/popData2019) %>%
  select(mortalityRate, countriesAndTerritories) %>%


  #eliminate unnecessary entries add world data 
  distinct() %>%
  right_join(world, by = c("countriesAndTerritories" = "region")) 
  


# visualizing

covid_data_wrapped_tbl %>%
  
  ggplot(aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill=mortalityRate), colour = "white") +
  
  
  scale_fill_gradient(labels = scales::percent_format(accuracy = 0.001),
                      low = "#FD7171", high = "#700A0A") +
  #scale_x_continuous() %>%
  


  theme(legend.position  = "right", 
        legend.direction = "vertical",
        plot.title = element_text(size =15),
        plot.subtitle = element_text(size = 13),
        plot.caption = element_text(size = 12),
        legend.title = element_text(size = 13),
        legend.text = element_text(size = 12),
        panel.grid = element_line(colour = "#AEABAB"),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.background = element_blank(),  
        plot.background = element_blank()
        )  +
    labs(
      title = "Cornfirmed COVID-19 death relative to the size of the population",
      subtitle = "More than 1.2 Million confirmed COVID-19 deaths worldwide",
      caption = "Date: 5/12/2020",
      x = "",
      y = "",
      fill = "Mortality Rate")



```


